## 네트워크 기본 상식

#### OSI 7 layer

------

계층 구분 이유? 통신 단계를 확인, 단계별로 이상시 수정 가능

1. **물리(Physical)** ex. 리피터, 케이블, 허브 등 데이터를 전기적인 신호로 변환해서 주고 받는 기능. 데이터 전송 역할
2. **데이터링크(DataLink)** ex. 브릿지, 스위치 등 물리 계층으로 송수신되는 정보를 관리하여 안전하게 전달되도록 도와주는 역할. **Mac주소**를 통해 통신하다. frame에 mac주소를 부여하고 **에러검출, 재전송, 흐름제어**를 진행한다.
3. **네트워크(Network)** ex. 라우터, IP 데이터를 목적지까지 가장 안전하고 빠르게 전달하는 기능을 담당한다. **라우터를 통해 이동할 경로를 선택**하고, **IP주소**를 지정해 해당 경로에 따라 패킷을 전달해준다. **라우팅, 흐름제어, 오류제어, 세그먼테이션** 등을 수행한다.
4. **전송(Transport)** ex. TCP, UDP **TCP**와 **UDP** 프로토콜을 통해 통신을 활성화한다. 포트를 열어두고, 프로그램들이 전송을 할 수 있도록 제공해준다. **TCP: 신뢰성, 연결지향적 UDP: 비신뢰성, 비연결성, 실시간**
5. **세션(Session)** ex. API, Socket 데이터가 통신하기 위한 논리적 연결을 담당한다. TCP/IP 세션을 만들고 없애는 책임을 지니고 있다.
6. **표현(Presentation)** ex. JPEG, MPEG등 데이터 표현에 대한 독립성을 제공하고 암호화하는 역할을 담당한다. 파일 인코딩, 명령어를 포장, 압축, 암호화한다.
7. **응용(Application)** ex. HTTP, FTP, DNS등 최종 목적지로, 응용 프로세스와 직접 관계하여 일반적인 응용 서비스를 수행한다. 사용자 인터페이스, 전자우편, 디비 관리 등의 서비스를 제공한다.



#### TCP 3 & 4 way handshake

------

' 네트워크 통신을 연결하고 해제하는 과정 '

[3 way handshake - 연결 성립]

TCP는 정확한 전송을 보장해야 한다. 따라서 통신하기에 앞서, 논리적인 접속을 성립하기 위해 3 way handshake 과정을 진행한다.

1. 클라이언트가 서버에게 SYN 패킷을 보냄(sequence: x)
2. 서버가 SYN(x)를 받고, 클라이언트에게 받았다는 신호인 ACK과 SYN 패킷을 보냄(sequence: y, ACK: x+1)
3. 클라이언트는 서버의 응답은 ACK(x+1)와 SYN(y) 패킷을 받고, ACK(y+1)를 서버로 보냄

⇒3번의 통신이 완료되면 연결이 성립된다.

[4 way handshake - 연결 해제]

연결 성립 후, 모든 통신이 끝나면 해제해야 한다.

1. 클라이언트는 서버에게 연결을 종료한다는 FIN 플래그를 보낸다.
2. 서버는 FIN을 받고, 확인했다는 ACK를 클라이언트에게 보낸다.(이때 모든 데이터를 보내기 위해 TIME OUT 상태가 된다.)
3. 데이터를 모두 보냈다면, 연결이 종료되었다는 FIN 플래그를 클라이언트에게 보낸다.
4. 클라이언트는 FIN을 받고, 확인했다는 ACK를 서버에게 보낸다. (아직 서버로부터 받지 못한 데이터가 있을 수 있으므로 TIME_WAIT을 통해 기다린다.)

서버는 ACK를 받은 이후 소켓을 닫는다(Closed) TIME_WAIT 시간이 끝나면 클라이언트도 닫는다.(Closed)

⇒ 4번의 통신이 완료되면 연결이 해제된다.



#### TCP/IP (흐름제어/혼잡제어)

------

[TCP 통신이란?]

- 네트워크 통신에서 신뢰적인 연결방식
- TCP는 기본적으로 unreliable network에서, reliable network를 보장할 수 있도록 하는 프로토콜
- TCP는 network congestion avoidance algorithm을 사용

[reliable network를 보장한다는 것은 4가지 문제점 존재]

1. 손실 : packet이 손실될 수 있는 문제
2. 순서 바뀜 : packet의 순서가 바뀌는 문제
3. Congestion : 네트워크가 혼잡한 문제
4. Overload : receiver가 overload되는 문제

[**흐름제어(Flow Control)**]

송신측과 수신측의 데이터 처리 속도 차이를 해결하기 위한 기법(송신측이 수신측보다 데이터 처리 속도가 빠른 경우)

- 수신측에서 제한된 저장 용량을 초과한 이후에 도착하는 데이터는 손실 된 수 있고, 손실되면 불필요한 응답과 데이터 전송이 빈번하게 발생
- flow control은 receiver가 packet을 지나치게 많이 받지 않도록 **조절**하는 것(송신측의 데이터 전송량을 수신측에 따라 조절한다.)
- 기본 개념은 receiver가 sender에게 현재 자신의 상태를 feedback한다는 점

해결방법

![Untitled](C:\Users\LEEJ\Downloads\Untitled.png)

1. stop and wait : 매번 전송한 패킷에 대해 확인 응답을 받아야만 그 다음 패킷을 전송하는 방법.
2. sliding window(GBn(Go-Back-n) 기법) : 수신측에서 설정한 윈도우 크기만큼 송신측에서 확인 응답없이 세그먼트를 전송할 수 있게 하여 데이터 흐름을 동적으로 조절하는 제어 방법.

- 목적 : 전송된 프레임이 손상되면 확인된 마지막 프레임 이후로 보내진 프레임을 재전송하는 기법.
- (마지막에 보내진 바이트 - 마지막에 확인된 바이트 <= 남아있는 공간) == (현재 공중에 떠있는 패킷 수 <= sliding window)
- 먼저 윈도우에 포함되는 모든 패킷을 전송하고, 그 패킷들의 전달이 확인되는 대로 이 윈도우를 옆으로 옮김으로 그 다음 패킷들을 전송.
- window : TCP/IP 를 사용하는 모든 호스트들은 송신하기 위한 것과 수신하기 위한 2개의 window를 가지고 있다. 호스트들은 실제 데이터를 보내기 전에 '3 way handshaking'을 통해 수신 호스트의 receive window size에 자신의 send window size를 맞추게 된다.

[**혼잡제어(congestion control)**]

송신측의 데이터 전달과 네트워크의 데이터 처리 속도 차이를 해결하기 위한 기법.

송신측의 데이터는 지역망이나 인터넷으로 연결된 대형 네트워크를 통해 전달된다. 만약 한 라우터에 데이터가 몰릴 경우, 자신에게 온 데이터를 모두 처리할 수 없게 된다. 이런 경우 호스트들은 또 다시 재전송을 하게되고 결국 혼잡만 가중시켜 오버플러우나 데이터 손실을 발생시키게 된다. 따라서 이러한 네트워크의 혼잡을 피하기 위해 송신측에서 보내는 데이터의 전송속도를 강제로 줄이게 되는데, 이러한 작업을 혼잡 제어라고 한다.

**네트워크 내에 패킷 수가 과도하게 증가**하는 현상을 **혼잡**이라고 하고, 혼잡 현상을 방지하거나 제거하는 기능을 **혼잡제어**라고 한다.

해결방법



- **AIMD(additive increase/multiplicative decrease)**
  - 처음에 패킷 1개씩, 문제없으면 window 크기(단위 시간 내에 보내는 패킷의 수)를 1씩 증가시켜가면서 전송
  - 패킷 전송에 실패하거나 일정 시간을 넘으면 패킷의 보내는 속도를 절반으로 줄인다.
  - 공평한 방식으로, 여러 호스트가 한 네트워크를 공유하고 있으면 나중에 진입하는 쪽이 처음에는 불리하지남, 시간이 흐르면 평형상태로 수렴하게 되는 특징이 있다.
  - 문제점은 초기에 네트워크의 높은 대역폭을 사용하지 못하여 오랜 시간이 걸리게 되고, 네트워크가 혼잡해지는 상황을 미리 감지하지 못한다. 네트워크가 혼잡해지고 나서야 대역폭을 줄이는 방식이다.
- **slow start(느린 시작)**
- AIMD 방식이 네트워크의 수용량 주변에서 효율적으로 작동하지만, 처음에는 전송 속도를 올리는데 시간이 오래 걸리는 단점이 존재.
- slow start방식은 AMID와 마찬가지로 패킷을 하나씩 보내면서 시작하고, 패킷이 문제없이 도착하면 각각의 ACK 패킷마다 window size를 1개씩 늘려준다. 주기가 지나면 window size가 2배가 된다.
- 전송속도는 지수 함수로 증가한다.
- 혼잡 현상이 발생하면 window size를 1로 떨어뜨린다.
- 처음에는 네트워크 수용량을 예상할 수 있는 정보가 없지만, 혼잡 현상이 발생하고 나면 네트워크의 수용량을 어느 정도 예상할 수 있다.
- 혼잡 현상이 발생했던 window size의 절반까지는 이전처럼 지수 함수로 window size를 증가시키고 그 이후부터는 완만하게 1씩 증가킨다.
- **fast retransmit(빠른 재전송)**
- TCP의 혼잡 조절에 추가된 정책
- 패킷을 받는 쪽에서 먼저 도착해야할 패킷이 도착하지 않고 다음 패킷이 도착한 경우에도 ACK 패킷을 보내게 된다.
- 단, 순서대로 잘 도착한 마지막 패킷의 다음 패킷의 순번을 ACK 패킷에 실어서 보내게 되므로, 중간에 하나가 손실되면 송신 측에서는 순번이 중복된 ACK패킷을 받게 된다. 이것을 감지하는 순간 문제가 되는 순번의 패킷을 재전송 해줄 수 있다.
- 중복된 순번의 패킷을 3개 받으면 재전송을 하게 된다. 약산 혼잡한 상황이 일어난 것이므로 혼잡을 감지하고 window size를 줄이게 된다.
- **fast recovery(빠른 회복)**
- 혼잡한 상태가 되면 window size를 1로 줄이지 않고 반으로 줄이고 선형증가시키는 방법이다. 이 정책까지 적용하면 혼잡 상황을 한 번 겪고 나서부터는 순수한 AIMD 방식으로 동작하게 된다.

**[전송의 전체 과정]**

- 응용계층 7 : sender 응용계층이 socket에 data를 쓴다.
- 수송계층 4 : data를 segment에 감싼다. 그리고 네트워크 계층 3에 넘겨준다.
- receiving node로 전송된다. 이때, sender의 send buffer에 data를 저장하고, receiver는 receive buffer에 data를 저장한다.
- application에서 준비가 되면 이 buffer에 있는 것을 읽기 시작한다.
- flow control의 핵심은 이 receiver buffer가 넘치지 않게 하는 것이다.
- recevier는 RWND(Receive Window) : receive buffer의 남은 공간을 홍보함.



#### UDP

------

- UDP(User Datagram Protocol)는 데이터를 데이터그램 단위로 처리하는 프로토콜이다.
- 비연결형, 신뢰성 없는 전송 프로토콜.
- 데이터그램 단위로 쪼개면서 전송을 해야하기 때문에 전송 계층이다.
- Transport layer에서 사용하는 프로토콜.

[**TCP / UDP 나오게 된 이유**]

1. IP의 역할은 host to host(장치 to 장치)만 지원한다. 장치에서 장치로 이동은 IP로 해결되지만, 하나의 장비안에서 수많은 프로그램들이 통신을 할 경우에는 IP만으로는 한계가 있다.
2. IP에서 오류가 발생하면 ICMP(인터넷 제어 메시지 프로토콜 : TCP/IP에서 IP 패킷을 처리할 때 발생되는 문제를 알리거나, 진단 등과 같이 IP 계층에서 필요한 기타 기능들을 수행하기위해 사용되는 프로토콜)에서 알려준다.

- 1번을 해결하기 위해 포트 번호가 나옴. 2번을 해결하기 위해 상위 프로토콜인 TCP와 UDP가 나옴.

**[어떻게 오류를 해결?]**

TCP - 데이터의 분실, 중복, 순서가 뒤바뀜 등을 자동으로 보정해줘서 송수신 데이터의 정확한 전달을 할 수 있도록 해준다.

UDP - IP가 제공한 정도의 수준만을 제공하는 간단한 IP 상위 계층의 프로토콜이다. TCP와는 다르게 에러가 날 수도 있고, 재전송이나 순서가 뒤바뀔 수도 있어서 이 경우, 어플리케이션에서 처리하는 번거로움이 존재한다.

**[UDP 왜 사용?]**

- 장점 : 데이터의 신속성, 데이터의 처리가 TCP보다 빠름.
- 주로 실시간 방송과 온라인 게임에서 사용된다. 네트워크 환경이 안 좋을때, 끊기는 현상을 생각하면 된다.

**[UDP 헤더]**

Source port : 시작 포트 (2byte)

destination port : 도착지 포트(2byte)

length : 길이(2byte)

Checksum : 오류 검출(2byte), 중복 검사의 한 형태로, 오류 정정을 통해 공간이나 시간 속에서 송신된 자료의 무결성을 보호하는 단순한 방법.

⇒ 간단해서, TCP보다 용량이 가볍고 송신 속도가 빠르게 작동됨. 그러나 확인 응답을 못하므로, TCP보다 신뢰도가 떨어짐. UDP는 비연결성, TCP는 연결성으로 정의.

**[DNS와 UDP 통신 프로토콜을 사용]**

DNS는 데이터를 교환하는 경우다.

TCP를 사용하게 되면 데이터를 송신할 때까지 세션 확립을 위한 처리를 하고, 송신한 데이터가 수신되었는지 점검하는 과정이 필요하므로, protocol overhead가 UDP에 비해서 크다. (TCP는 reliable, UDP는 unreliable)

**[DNS는 왜 UDP사용?]**

1. TCP가 3-way handshake를 사용하는 반면, UDP는 connection을 유지할 필요가 없음.
2. DNS request는 UDP segment에 들어갈 정도로 작음.
3. UDP는 not reliable이나, reliability는 application layer에 추가될 수 있음.(timeout 추가나, resend 작업을 통해)

DNS는 UDP를 53번 port에서 사용함.

그러나 TCP를 사용하는 경우가 있음.

Zone transfer 을 사용해야하는 경우에는 TCP를 사용해야 함.

(Zone Transfer : DNS 서버 간의 요청을 주고 받을 떄 사용하는 transfer)

만약에 데이터가 512 bytes를 넘거나, 응답을 못받은 경우 TCP로 함.



#### 대칭키 & 공개키

------

**[대칭키]**

암호화의 복호화에 같은 암호키(대칭키)를 사용하는 알고리즘

동일한 키를 주고받기 때문에 매우 빠르다는 장점.

대칭키 전달과정에서 해킹 위험에 노출되는 단점.

**[공개키]**

암호화와 복호화에 사용하는 암호키를 분리한 알고리즘

자신이 가지고 있는 고유한 암호키(비밀키)로만 복호화할 수 있는 암호키(공개키)를 대중에 공개함.

**[공개키 암호화 방식]**

1. a가 웹 상에 공개된 'b의 공개키'를 이용해 평문을 암호화하여 b에게 보냄.
2. b는 자신의 비밀키로 복호화한 평문을 확인,  a의 공개키로 응답을 암호화하여 a에게 보냄.
3. a는 자신의 비밀키로 암호화된 응답문을 복호화함.

대칭키의 단점은 해결, 암호화 복호화가 복잡(암/복호화 키가 서로 다르기 때문)

[대칭키와 공개키 암호화 방식을 적절히 혼합해보면?]

⇒ **SSL 탄생의 시초**

1. a가 b의 공개키로 암호화 통신에 사용할 대칭키를 암호화하고 b에게 보냄.
2. b는 암호문을 받고, 자신의 비밀키로 복호화함
3. b는 a로부터 얻은 대칭키로 a에게 보낼 평문을 암호화하여 a에게 보냄
4. a는 자신의 대칭키로 암호문을 복호화함
5. 앞으로는 이 대칭키로 암호화를 통신함

즉, 대칭키를 주고받을 때만 공개키 암호화 방식을 사용하고 이후에는 계속 대칭키 암호화 방식으로 통신한다.



#### HTTP & HTTPS

------

**[HTTP(Hyper Text Transfer Protocol)]**

인터넷 상에서 클라이언트와 서버가 자원을 주고 받을 때 쓰는 통신 규약.

HTTP는 텍스트 교환이므로, 누군가 네트워크에서 신호를 가로채면 내용이 노출되는 보안 이슈가 존재함.

이런 보안 문제를 해결해주는 프로토콜 'HTTPS'

**[HTTPS(Hyper Text Transfer Protocol Secure)]**

인터넷 상에서 정보를 암호화하는 **SSL** 프로토콜을 사용해 클라이언트와 서버가 자원을 주고 받을 때 쓰는 통신 규약

HTTPS는 텍스트를 암호화한다.(공개키 암호화 방식)

**[HTTPS 통신 흐름]**

1. 애플리케이션 서버(A)를 만드는 기업은 HTTPS를 적용하기 위해 공개키와 개인키를 만든다.
2. 신뢰할 수 있는 CA 기업을 선택하고, 그 기업에게 내 공개키 관리를 부탁하며 계약을 한다. CA : Certificate Authority로, 공개키를 저장해주는 신뢰성이 검증된 민간기업
3. 계약 완료된 CA 기업은 해당 기업의 이름, A서버 공개키, 공개키 암호화 방법을 담은 인증서를 만들고, 해당 인증서를 CA 기업의 개인키로 암호화해서 A서버에게 제공한다.
4. A서버는 암호화된 인증서를 갖게 된다. 이제 A서버는 A서버의 공개키로 암호화된 HTTPS 요청이 아닌 요청이 오면, 이 암호화된 인증서를 클라이언트에게 준다.
5. 클라이언트는 main.html 파일을 달라고 A서버에 요청했다고 가정) HTTPS 요청이 아니기 때문에 CA기업이 A서버의 정보를 CA기업의 개인키로 암호환 인증서를 받게 된다. CA 기업의 공개키는 브라우저가 이미 알고 있다.(세계적으로 신뢰할 수 있는 기업으로 등록되어 있기 때문에 브라우저가 인증서를 탐색하여 해독이 가능)
6. 브라우저는 해독한 뒤 A서버의 공개키를 얻게 되었다. 이제 A서버와 통신할 때는 얻는 A서버의 공개키로 암호화해서 요청을 날리게 된다.

HTTPS도 무조건 안전한 것은 아니다.(신뢰받는 CA기업이 안니 자체 인증서 발급한 경우 등)

이때는 HTTPS지만 브라우저에서 주의요함, 안전하지 않은 사이트 와 같은 알림으로 주의 받게 된다.



#### 로드 밸런싱(Load Balancing)

------

둘 이상의 CPU or 저장장치와 같은 컴퓨터 자원들에게 작업을 나눠주는 것

웹사이트 접속하는 인원 증가로 트래픽을 많아서 서버 1대로는 대응 불가능.

1. 하드웨어의 성능을 올리기(scale-up)
2. 여러대의 서버가 나눠서 일하기(scale-out)

2번의 여러 서버에게 균등하게 트래픽을 분산시켜주는 것이 **로드 밸런싱**

로드 밸런싱은 분산식 웹 서비스로, 여러 서버에 부하(load)를 나누어주는 역할.

로드 밸런서를 클라이언트와 서버 사이에 두고, 부하가 일어나지 않도록 여러 서버에 분산시켜주는 방식. 서비스를 운영하는 사이트의 규모에 따라 웹 서버를 추가로 증설하면서 로드 밸런서로 관리해주면서 웹 서버의 부하를 해결할 수 있다.

[로드 밸런서가 서버를 선택하는 방식]

- 라운드 로빈(Round robin) : 시분할 시스템을 위해 설계된 선점형 스케줄링의 하나로서, 프로세스들 사이에 우선순위를 두지 않고, 순서대로 시간단위(Time Quantum)로 CPU를 할당하는 방식의 CPU 스케줄링 알고리즘,

  컴퓨터 자원을 사용할 수 있는 기회를 프로그램 프로세스들에게 공정하게 부여하기 위한 한 방법으로서, 각 프로세스에 일정시간을 할당하고, 할당된 시간이 지나면 그 프로세스는 잠시 보류한 뒤 다른 프로세스에게 기회를 주고, 또 그 다음 프로세스에게 하는 식으로, 돌아가며 기회를 부여하는 운영방식이라 풀어 말할 수 있겠습니다.

- least connections : 연결 개수가 가장 적은 서버 선택(트래픽으로 인해 세션이 길어지는 경우 권장)

- source : 사용자 ip를 해싱해 분배(특정 사용자가 항상 같은 서버로 연결되는 것 보장)

[로드 밸러서 장애 대비]

서버를 분배하는 로드밸런서에 문제가 생길 수 있기 때문에 로드 밸런서를 이중화하여 대비한다. (active 상태와 passive 상태)



#### Blocking I/O & Non-Blocking I/O

------

I/O 작업은 Kernel level에서만 수행할 수 있다. 따라서, process, thread는 커널에게 I/O를 요청해야 한다.

[Blocking I/O**]**

I/O Blocking 형태의 작업은

1. process(thread)가 kernel에게 I/O를 요청하는 함수를 호출
2. kernel이 작업을 완료하면 작업 결과를 반환 받음.

특징 :

- I/O작업이 진행되는 동안 user process(thread)는 자신의 작업을 중단한 채 대기
- Resource 낭비가 심함 (I/O작업이 cpu 자원을 거의 쓰지 않음)

여러 클라이언트가 접속하는 서버를 Blocking 방식으로 구현하는 경우 → I/O작업을 진행하는 작업을 중지 → 다른 클라이언트가 진행중인 작업을 중지하면 안되므로, 클라이언트 별로 별도의 thread를 생성해야 함 → 접속자 수가 매우 많아짐.

이로 인해, 많아진 threads로 컨텍스트 스위칭 횟수가 증가함. 비효율적인 동작 방식.

[non-blocking I/O]

I/O 작업이 진행되는 동안 user process의 작업을 중단하지 않음.

진행 순서 :

1. user process가 recvfrom 함수 호출(커널에서 해당 socket으로부터 data를 받고 싶다고 요청함)

2. kernel은 이 요청에 대해, 곧바도 recvBuffer를 채워서 보내지 못하므로, "EWOULDBLOCK"을 return함.

3. blocking 방식과 달리, user process는 다른 작업을 진행할 수 있음.

4. recvBuffer에 user가 받을 수 있는 데이터가 있는 경우, buffer로부터 데이터를 복사하여 받아옴.

   ⇒ 이때, recvBuffer는 kernel이 가지고 있는 메모리에 적재되어 있으므로, memory간 복사로 인해, I/O보다 훨씬 빠른 속도로 data를 받아올 수 있다.

5. recvfrom 함수는 빠른 속도로 data를 복사한 후, 복사한 data의 길이와 함께 반환함.